/**
 * Generated by apidoc - http://www.apidoc.me
 * Service version: 0.0.1-SNAPSHOT
 * apidoc:0.11.21 http://dockerhost:9000/movio.cinema/apidoc-generator-reference/0.0.1-SNAPSHOT/jack-testkafka_0_8
 */

import java.util.Properties

import scala.language.postfixOps
import scala.annotation.tailrec
import scala.util.matching.Regex

import com.typesafe.config.Config

import kafka.consumer._
import kafka.message.MessageAndMetadata
import kafka.serializer.StringDecoder

import play.api.libs.json.Json

import movio.api.kafka_0_8.KafkaConsumer

package movio.cinema.apidoc.generator.reference.v0.kafka {
  import movio.cinema.apidoc.generator.reference.v0.models._
  import movio.cinema.apidoc.generator.reference.v0.models.json._

  object KafkaPersonTopic {
    /**
      The version of the api - apidoc generator enforces this value.
      For use when creating a topic name.
      Example: "v2"
      */
    val apiVersion = "v0"

    /**
      The name of the kafka topic to publish and consume messages from.
      This is a scala statedment/code that that gets executed
      Example: `s"mc-servicename-${apiVersion}-${tenant}"`

      @param tenant is the customer id, eg vc_regalus
      */
    def topic(tenant: String) = s"mc-person-master-${tenant}"

    val topicRegex = s"mc-person-master-" + "(.*)"
  }

  object KafkaPersonConsumer {
    val base = "movio.cinema.apidoc.generator.reference.kafka.consumer"
    val KafkaOffsetStorageType = s"$base.offset-storage-type"
    val KafkaOffsetStorageDualCommit = s"$base.offset-storage-dual-commit"
    val ConsumerTimeoutKey = s"$base.timeout.ms"
    val ConsumerZookeeperConnectionKey = s"$base.zookeeper.connection"
  }

  /**
    If you choose to override `topicRegex`, make sure the first group captures
    the tenant names.
   */
  class KafkaPersonConsumer (
    config: Config,
    consumerGroupId: String,
    topicRegex: Regex = KafkaPersonTopic.topicRegex.r
  ) extends KafkaConsumer[KafkaPerson] {
    import KafkaPersonConsumer._

    val topicFilter = new Whitelist(topicRegex.toString)

    lazy val consumerConfig = new ConsumerConfig(readConsumerPropertiesFromConfig)
    lazy val consumer = Consumer.create(consumerConfig)

    lazy val stream: KafkaStream[String, String] =
      consumer.createMessageStreamsByFilter(topicFilter, 1, new StringDecoder, new StringDecoder).head

    lazy val iterator = stream.iterator()

    def readConsumerPropertiesFromConfig = {
      val properties = new Properties

      properties.put("group.id", consumerGroupId)
      properties.put("zookeeper.connect", config.getString(ConsumerZookeeperConnectionKey))
      properties.put("auto.offset.reset", "smallest")
      properties.put("consumer.timeout.ms", config.getString(ConsumerTimeoutKey))
      properties.put("consumer.timeout", config.getString(ConsumerTimeoutKey))
      properties.put("auto.commit.enable", "false")

      properties.put("offsets.storage", config.getString(KafkaOffsetStorageType))
      properties.put("dual.commit.enabled", config.getString(KafkaOffsetStorageDualCommit))

      properties
    }

    def processBatchThenCommit(
      processor: Map[String, Seq[KafkaPerson]] ⇒ scala.util.Try[Map[String, Seq[KafkaPerson]]],
      batchSize: Int = 1
    ): scala.util.Try[Map[String, Seq[KafkaPerson]]] = {
      @tailrec
      def fetchBatch(remainingInBatch: Int, messages: Map[String, Seq[KafkaPerson]]): scala.util.Try[Map[String, Seq[KafkaPerson]]] ={
        if (remainingInBatch == 0) {
          scala.util.Success(messages)
        } else {
          // FIXME test
          scala.util.Try {
            iterator.next()
          } match {
            case scala.util.Success(message) =>
              val payload = message.message
              val newMessages = 
                if (payload != null) {
                  val entity = Json.parse(payload).as[KafkaPerson]
                  val topicRegex(tenant) = message.topic
  
                  val newSeq = messages.get(tenant).getOrElse(Seq.empty) :+ entity
                  
                  messages + (tenant -> newSeq)
                } else {
                  messages
                }
              
              fetchBatch(remainingInBatch - 1, newMessages)
            case scala.util.Failure(ex) => ex match {
              case ex: ConsumerTimeoutException ⇒
                // Consumer timed out waiting for a message. Ending batch.
                scala.util.Success(messages)
              case ex =>
                scala.util.Failure(ex)
            }
          }
        }
      }

      fetchBatch(batchSize, Map.empty) match {
        case scala.util.Success(messages) =>
          processor(messages) map { allMessages =>
            consumer.commitOffsets(true)
            allMessages
          }
        case scala.util.Failure(ex) => scala.util.Failure(ex)
      }
    }

    def shutdown() = consumer.shutdown()
  }
}

